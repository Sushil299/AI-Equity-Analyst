# -*- coding: utf-8 -*-
"""backend

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UMPFrnSiYVrOpvw5fv4SMpnmB-e-CE9z
"""

import os
import datetime
import psycopg2
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import FileResponse
import google.generativeai as genai
import fitz  # PyMuPDF for PDF processing

# ✅ Load PostgreSQL Database URL from Environment Variables
DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise Exception("DATABASE_URL is not set. Please configure it in Render.")

# ✅ Connect to PostgreSQL
conn = psycopg2.connect(DATABASE_URL)
cursor = conn.cursor()

# ✅ Create Table if not exists
cursor.execute("""
CREATE TABLE IF NOT EXISTS summaries (
    id SERIAL PRIMARY KEY,
    company_name TEXT NOT NULL,
    document_date TEXT NOT NULL,
    document_type TEXT NOT NULL,
    filename TEXT NOT NULL,
    summary TEXT NOT NULL
)
""")
conn.commit()

# ✅ Configure Gemini AI API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise Exception("GEMINI_API_KEY not set in environment variables.")
genai.configure(api_key=GEMINI_API_KEY)

# ✅ Initialize FastAPI
app = FastAPI()

# ✅ Function to extract text from PDF
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = "\n".join([page.get_text("text") for page in doc])
    return text

# ✅ API: Upload File (Overwrites Existing)
@app.post("/upload/")
async def upload_file(
    file: UploadFile = File(...),
    company_name: str = Form(...),
    document_date: str = Form(...),
    document_type: str = Form(...)
):
    try:
        # ✅ Validate Date Format
        try:
            datetime.datetime.strptime(document_date, "%Y-%m-%d")
        except ValueError:
            pass

        # ✅ Check if a document of the same type already exists
        cursor.execute("""
            SELECT filename FROM summaries WHERE company_name = %s AND document_type = %s
        """, (company_name, document_type))
        existing_record = cursor.fetchone()

        if existing_record:
            # ✅ Remove old database entry
            cursor.execute("""
                DELETE FROM summaries WHERE company_name = %s AND document_type = %s
            """, (company_name, document_type))
            conn.commit()

        # ✅ Save new file locally
        file_path = f"./uploads/{file.filename}"
        with open(file_path, "wb") as f:
            f.write(await file.read())

        # ✅ Extract text from PDF
        text = extract_text_from_pdf(file_path)

        # ✅ Store in PostgreSQL
        cursor.execute("""
            INSERT INTO summaries (company_name, document_date, document_type, filename, summary)
            VALUES (%s, %s, %s, %s, %s)
        """, (company_name, document_date, document_type, file.filename, text))
        conn.commit()

        return {"message": "✅ File uploaded successfully & previous document overwritten."}

    except Exception as e:
        conn.rollback()
        raise HTTPException(status_code=500, detail=f"Failed to upload file: {str(e)}")

# ✅ API: Fetch All Companies
@app.get("/companies")
async def get_companies():
    cursor.execute("SELECT DISTINCT company_name FROM summaries")
    companies = [row[0] for row in cursor.fetchall()]
    return {"companies": companies} if companies else {"message": "No companies found."}

# ✅ API: Generate Comprehensive Analysis
@app.get("/summary/{company_name}")
async def get_summary(company_name: str):
    cursor.execute("SELECT document_type, summary FROM summaries WHERE company_name = %s", (company_name,))
    rows = cursor.fetchall()

    if not rows:
        return {"message": "No documents found for this company."}

    doc_texts = {doc_type: summary for doc_type, summary in rows}

    # ✅ AI Prompt
    ai_prompt = f"""
    Generate a structured **equity research report** for {company_name}.

    **1. Executive Summary**
    **2. Key Financial Highlights** (Show in Markdown table)
    **3. Business & Operational Highlights**
    **4. Market & Competitive Positioning**
    **5. Valuation & Outlook**

    **Available Data Sources:**
    - Annual Report: {doc_texts.get('Annual Report', 'Not available')}
    - Earnings Call Transcript: {doc_texts.get('Earnings Call Transcript', 'Not available')}
    - Investor Presentation: {doc_texts.get('Investor Presentation', 'Not available')}
    - Analyst Call Transcript: {doc_texts.get('Analyst Call Transcript', 'Not available')}
    """

    model = genai.GenerativeModel("gemini-1.5-flash")
    response = model.generate_content(ai_prompt)
    return {"Company Name": company_name, "Comprehensive Analysis": response.text}

# ✅ API: Admin Panel Summary
@app.get("/admin-summary")
async def get_admin_summary():
    cursor.execute("""
        SELECT company_name,
               MAX(CASE WHEN document_type = 'Annual Report' THEN 'Yes' ELSE 'No' END) AS annual_report,
               MAX(CASE WHEN document_type = 'Quarterly Report' THEN 'Yes' ELSE 'No' END) AS quarterly_report,
               MAX(CASE WHEN document_type = 'Earnings Call Transcript' THEN 'Yes' ELSE 'No' END) AS earnings_call,
               MAX(CASE WHEN document_type = 'Investor Presentation' THEN 'Yes' ELSE 'No' END) AS investor_presentation,
               MIN(document_date) AS created_date,
               MAX(document_date) AS last_updated_date
        FROM summaries
        GROUP BY company_name
    """)
    rows = cursor.fetchall()

    return {"companies": [
        {"Company Name": row[0], "Annual Report": row[1], "Quarterly Report": row[2],
         "Earnings Call Transcript": row[3], "Investor Presentation": row[4],
         "Created Date": row[5], "Last Updated Date": row[6]} for row in rows
    ]}